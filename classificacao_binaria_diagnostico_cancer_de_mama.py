# -*- coding: utf-8 -*-
"""classificacao_binaria_diagnostico_cancer_de_mama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GmPhB6cOcLpcIzVSjSLUhPR4q7KGwrVo
"""

!pip install scikeras

import os
import sys
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# Função utilitária para carregar dados de forma robusta
def carregar_dados(dados_path="dados_breast.csv", rotulos_path="rotulos_breast.csv"):
    if os.path.exists(dados_path) and os.path.exists(rotulos_path):
        X = pd.read_csv(dados_path)
        y = pd.read_csv(rotulos_path, header=None)

        # Alinhar comprimentos, caso haja discrepância
        if len(y) > len(X):
            y = y.iloc[: len(X)]
        elif len(X) > len(y):
            X = X.iloc[: len(y)]
        y.columns = ["diagnostico"]

        return X, y["diagnostico"]
    else:
        # Fallback para sklearn
        from sklearn.datasets import load_breast_cancer
        data = load_breast_cancer(as_frame=True)
        X = data.frame[data.feature_names]
        y = data.target

        return X, y

# Carregar dados
X, y = carregar_dados()
print("Dataset carregado. Formato:", X.shape, y.shape)

# Verificações básicas
if X.isna().sum().sum() > 0:
    print("Existem valores ausentes — aplicando preenchimento por mediana.")
    X = X.fillna(X.median())

# Divisão treino/teste (estratificada)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Split realizado — treino/teste:", X_train.shape, X_test.shape)

# Normalização (muito importante para Keras e para vizinhança de otimização)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Tenta importar tensorflow; se não estiver disponível, faz fallback para sklearn MLPClassifier
USE_TF = True
try:
    import tensorflow as tf
    from tensorflow import keras
    # Também importaremos o wrapper do TF para scikit-learn, se disponível
    from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
    print("TensorFlow disponível. Usaremos Keras para treinar a rede.")
except Exception as e:
    USE_TF = False
    print("TensorFlow não encontrado ou não utilizável. Fallback para scikit-learn MLPClassifier.")

# ----------------------- Backend Keras (TensorFlow) -----------------------
if USE_TF:
    def criar_modelo_keras(neurons=16, optimizer="adam"):
        model = keras.Sequential([
            keras.layers.Input(shape=(X_train_scaled.shape[1],)),
            keras.layers.Dense(neurons, activation="relu"),
            keras.layers.Dense(neurons, activation="relu"),
            keras.layers.Dense(1, activation="sigmoid"),
        ])
        model.compile(optimizer=optimizer, loss="binary_crossentropy", metrics=["binary_accuracy"])
        return model

    # Wrapper para compatibilidade com scikit-learn
    keras_clf = KerasClassifier(build_fn=criar_modelo_keras, epochs=50, batch_size=16, verbose=0)

    # Validação cruzada rápida para verificar funcionamento (3 folds para velocidade)
    kfold = KFold(n_splits=3, shuffle=True, random_state=42)
    print("Executando cross_val_score (Keras) — 3 folds (pode demorar)...")
    cv_scores = cross_val_score(keras_clf, scaler.transform(X), y, cv=kfold, scoring="accuracy")
    print("CV scores:", cv_scores, "média:", cv_scores.mean())

    # GridSearch (exemplo pequeno para não demorar muito)
    param_grid = {
        "neurons": [8, 16],
        "optimizer": ["adam", "rmsprop"],
        "epochs": [30],
    }
    grid = GridSearchCV(keras_clf, param_grid, cv=3, scoring="accuracy", verbose=1)
    print("Iniciando GridSearch (pode demorar).")
    grid.fit(scaler.transform(X), y)
    print("Melhor combinação (GridSearch):", grid.best_params_, "->", grid.best_score_)

    # Treinamento final com melhores parâmetros
    best_params = grid.best_params_
    modelo_final = criar_modelo_keras(neurons=best_params.get("neurons", 16), optimizer=best_params.get("optimizer", "adam"))
    history = modelo_final.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test),
                               epochs=best_params.get("epochs", 30), batch_size=16, verbose=1)

    # Avaliação
    y_pred_proba = modelo_final.predict(X_test_scaled).ravel()
    y_pred = (y_pred_proba > 0.5).astype(int)
    print("Acurácia (teste):", accuracy_score(y_test, y_pred))
    print("Matriz de confusão:\n", confusion_matrix(y_test, y_pred))
    print("Relatório de classificação:\n", classification_report(y_test, y_pred))

    # Salvar modelo Keras e scaler
    modelo_dir = "modelo_keras_breast"
    os.makedirs(modelo_dir, exist_ok=True)
    modelo_final.save(os.path.join(modelo_dir, "modelo_keras.h5"))
    import joblib
    joblib.dump(scaler, os.path.join(modelo_dir, "scaler.joblib"))
    print(f"Modelo e scaler salvos em: {modelo_dir}")

# ----------------------- Backend scikit-learn (MLPClassifier) -----------------------
else:
    from sklearn.neural_network import MLPClassifier

    # Pipeline: scaler + MLP
    pipe = Pipeline([
        ("scaler", StandardScaler()),
        ("mlp", MLPClassifier(max_iter=500, random_state=42))
    ])

    # Cross-validation rápida
    kfold = KFold(n_splits=3, shuffle=True, random_state=42)
    print("Executando cross_val_score (MLPClassifier) — 3 folds...")
    cv_scores = cross_val_score(pipe, X, y, cv=kfold, scoring="accuracy")
    print("CV scores:", cv_scores, "média:", cv_scores.mean())

    # GridSearch de exemplo
    param_grid = {
        "mlp__hidden_layer_sizes": [(16,16), (32,)],
        "mlp__activation": ["relu", "tanh"],
        "mlp__alpha": [0.0001, 0.001]
    }
    grid = GridSearchCV(pipe, param_grid, cv=3, scoring="accuracy", verbose=1)
    print("Iniciando GridSearch (MLP) — pode demorar.")
    grid.fit(X, y)
    print("Melhor combinação (GridSearch):", grid.best_params_, "->", grid.best_score_)

    # Treinamento final com melhores parâmetros
    modelo_final = grid.best_estimator_
    modelo_final.fit(X_train, y_train)

    # Avaliação
    y_pred = modelo_final.predict(X_test)
    print("Acurácia (teste):", accuracy_score(y_test, y_pred))
    print("Matriz de confusão:\n", confusion_matrix(y_test, y_pred))
    print("Relatório de classificação:\n", classification_report(y_test, y_pred))

    # Salvar modelo
    import joblib
    joblib.dump(modelo_final, "modelo_mlp_breast.joblib")
    print("Modelo salvo: modelo_mlp_breast.joblib")

print("Script finalizado. Revise os outputs e os artefatos salvos para confirmar resultados.")
